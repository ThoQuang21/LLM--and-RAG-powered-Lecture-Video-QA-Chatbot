# =======================================================
# STREAMLIT APP - H·ªÜ TH·ªêNG H·ªéI ƒê√ÅP V·ªöI RAG
# =======================================================
import streamlit as st
import sys
import os
from optimize_latency import (
    tai_model_embedding,
    tai_model_reranker,
    ket_noi_chromadb,
    thiet_lap_gemini,
    get_rag_answer_pipeline
)

# Th√¥ng ƒëi·ªáp fallback khi kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi trong b·ªëi c·∫£nh
FALLBACK_MESSAGE = "T√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin n√†y trong b·ªëi c·∫£nh ƒë∆∞·ª£c cung c·∫•p."

# =======================================================
# C·∫§U H√åNH TRANG
# =======================================================
st.set_page_config(
    page_title="ü§ñ H·ªá Th·ªëng H·ªèi ƒê√°p RAG",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# =======================================================
# KH·ªûI T·∫†O MODELS (CACHED)
# =======================================================
@st.cache_resource
def khoi_tao_models():
    """
    Kh·ªüi t·∫°o t·∫•t c·∫£ c√°c models v√† components m·ªôt l·∫ßn duy nh·∫•t.
    S·ª≠ d·ª•ng cache ƒë·ªÉ tr√°nh reload m·ªói l·∫ßn ng∆∞·ªùi d√πng ƒë·∫∑t c√¢u h·ªèi.
    """
    # C·∫•u h√¨nh
    DB_PATH = "my_rag_db_2"
    COLLECTION_NAME = "bai_giang_videos"
    EMBEDDING_MODEL_NAME = 'VoVanPhuc/sup-SimCSE-VietNamese-phobert-base'
    RERANKER_MODEL_NAME = 'cross-encoder/mmarco-mMiniLMv2-L12-H384-v1'
    GEMINI_API_KEY = 'AIzaSyAqJn039l1ThNaNATJ_4wTIgHv0hrxKRWE'
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # Kh·ªüi t·∫°o t·ª´ng component
    status_text.text("üîÑ ƒêang t·∫£i Embedding Model...")
    progress_bar.progress(10)
    model_embed = tai_model_embedding(EMBEDDING_MODEL_NAME)
    
    status_text.text("üîÑ ƒêang t·∫£i Reranker Model...")
    progress_bar.progress(30)
    model_rerank = tai_model_reranker(RERANKER_MODEL_NAME)
    
    status_text.text("üîÑ ƒêang k·∫øt n·ªëi ChromaDB...")
    progress_bar.progress(50)
    rag_collection = ket_noi_chromadb(DB_PATH, COLLECTION_NAME)
    
    status_text.text("üîÑ ƒêang thi·∫øt l·∫≠p Gemini...")
    progress_bar.progress(70)
    llm_model = thiet_lap_gemini(GEMINI_API_KEY)
    
    progress_bar.progress(100)
    status_text.text("‚úÖ ƒê√£ t·∫£i xong t·∫•t c·∫£ models!")
    
    # Ki·ªÉm tra l·ªói
    if not all([model_embed, model_rerank, rag_collection, llm_model]):
        st.error("‚ùå L·ªói: Kh√¥ng th·ªÉ kh·ªüi t·∫°o m·ªôt ho·∫∑c nhi·ªÅu components!")
        return None
    
    return {
        "embedding_model": model_embed,
        "reranker_model": model_rerank,
        "collection": rag_collection,
        "llm_model": llm_model
    }

# =======================================================
# H√ÄM X·ª¨ L√ù C√ÇU H·ªéI
# =======================================================
def xu_ly_cau_hoi(query, models, per_query_k=5, max_docs_to_rerank=20, rerank_batch_size=32):
    """
    X·ª≠ l√Ω c√¢u h·ªèi v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ t·ª´ pipeline RAG.
    """
    try:
        # T·∫°o placeholder cho progress
        progress_placeholder = st.empty()
        
        result = get_rag_answer_pipeline(
            original_query_text=query,
            llm_model=models["llm_model"],
            embedding_model=models["embedding_model"],
            collection=models["collection"],
            reranker=models["reranker_model"],
            per_query_k=per_query_k,
            max_docs_to_rerank=max_docs_to_rerank,
            rerank_batch_size=rerank_batch_size
        )
        
        # X√≥a placeholder sau khi ho√†n th√†nh
        progress_placeholder.empty()
        return result
    except Exception as e:
        st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω c√¢u h·ªèi: {e}")
        import traceback
        with st.expander("Chi ti·∫øt l·ªói"):
            st.code(traceback.format_exc())
        return None

# =======================================================
# GIAO DI·ªÜN CH√çNH
# =======================================================
def main():
    # Header
    st.title("ü§ñ H·ªá Th·ªëng H·ªèi ƒê√°p RAG")
    st.markdown("---")
    st.markdown("""
    H·ªá th·ªëng h·ªèi ƒë√°p th√¥ng minh s·ª≠ d·ª•ng RAG (Retrieval-Augmented Generation).
    Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v√† nh·∫≠n c√¢u tr·∫£ l·ªùi k√®m link YouTube tham kh·∫£o.
    """)
    
    # Sidebar cho c·∫•u h√¨nh
    with st.sidebar:
        st.header("‚öôÔ∏è C·∫•u h√¨nh")
        st.markdown("---")
        
        per_query_k = st.slider("S·ªë l∆∞·ª£ng docs m·ªói query (per_query_k)", 3, 10, 5)
        max_docs_to_rerank = st.slider("S·ªë l∆∞·ª£ng docs ƒë·ªÉ re-rank", 10, 30, 20)
        rerank_batch_size = st.slider("Batch size cho re-ranker", 16, 64, 32)
        
        st.markdown("---")
        st.markdown("### üí° G·ª£i √Ω")
        st.info("""
        - Gi·∫£m `per_query_k` ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô
        - Gi·∫£m `max_docs_to_rerank` ƒë·ªÉ gi·∫£m th·ªùi gian re-ranking
        - TƒÉng batch size n·∫øu c√≥ GPU m·∫°nh
        """)
    
    # Kh·ªüi t·∫°o models
    if 'models_loaded' not in st.session_state:
        with st.container():
            st.info("üîÑ ƒêang kh·ªüi t·∫°o models l·∫ßn ƒë·∫ßu ti√™n... Vui l√≤ng ƒë·ª£i trong gi√¢y l√°t...")
            models = khoi_tao_models()
            if models:
                st.session_state.models_loaded = True
                st.session_state.models = models
                st.success("‚úÖ ƒê√£ kh·ªüi t·∫°o th√†nh c√¥ng! B·∫°n c√≥ th·ªÉ ƒë·∫∑t c√¢u h·ªèi.")
                st.balloons()
                st.rerun()
            else:
                st.error("‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o models. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh.")
                st.stop()
    else:
        models = st.session_state.models
        st.success("‚úÖ Models ƒë√£ s·∫µn s√†ng!")
    
    st.markdown("---")
    
    # √î nh·∫≠p c√¢u h·ªèi
    st.subheader("üìù Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n")
    query = st.text_area(
        "C√¢u h·ªèi:",
        placeholder="V√≠ d·ª•: Attention kh√°c Self-Attention ·ªü ƒëi·ªÉm n√†o?",
        height=100,
        key="query_input"
    )
    
    # N√∫t g·ª≠i
    col1, col2, col3 = st.columns([1, 1, 4])
    with col1:
        submit_button = st.button("üöÄ G·ª≠i c√¢u h·ªèi", type="primary", use_container_width=True)
    with col2:
        clear_button = st.button("üóëÔ∏è X√≥a", use_container_width=True)
    
    if clear_button:
        st.session_state.query_input = ""
        st.rerun()
    
    # X·ª≠ l√Ω khi ng∆∞·ªùi d√πng g·ª≠i c√¢u h·ªèi
    if submit_button and query:
        # Hi·ªÉn th·ªã th√¥ng b√°o ƒëang x·ª≠ l√Ω
        status_container = st.container()
        with status_container:
            st.info(f"üîÑ ƒêang x·ª≠ l√Ω c√¢u h·ªèi: **{query}**\n\nVui l√≤ng ƒë·ª£i trong gi√¢y l√°t...")
        
        result = xu_ly_cau_hoi(
            query, 
            models,
            per_query_k=per_query_k,
            max_docs_to_rerank=max_docs_to_rerank,
            rerank_batch_size=rerank_batch_size
        )
        
        # X√≥a th√¥ng b√°o ƒëang x·ª≠ l√Ω
        status_container.empty()
        
        if result:
            st.markdown("---")
            st.subheader("üí¨ K·∫øt qu·∫£")
            
            # Hi·ªÉn th·ªã c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi
            col1, col2 = st.columns([1, 3])
            with col1:
                st.markdown("**‚ùì C√¢u h·ªèi:**")
            with col2:
                st.markdown(f"*{query}*")
            
            answer = result.get("answer", "Kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi")
            st.markdown("**ü§ñ Tr·∫£ l·ªùi:**")
            st.success(answer)
            
            answer_is_fallback = answer.strip() == FALLBACK_MESSAGE
            
            # Hi·ªÉn th·ªã link YouTube (n·∫øu c√≥) v√† c√¢u tr·∫£ l·ªùi kh√¥ng ph·∫£i fallback
            source_url = result.get("source_url")
            if source_url and not answer_is_fallback:
                st.markdown("---")
                st.subheader("üîó Ngu·ªìn tham kh·∫£o")
                
                # Ki·ªÉm tra xem c√≥ ph·∫£i link YouTube kh√¥ng
                if "youtube.com" in source_url or "youtu.be" in source_url:
                    # L·∫•y video ID ƒë·ªÉ embed
                    video_id = None
                    if "watch?v=" in source_url:
                        video_id = source_url.split("watch?v=")[1].split("&")[0]
                    elif "youtu.be/" in source_url:
                        video_id = source_url.split("youtu.be/")[1].split("?")[0]
                    
                    if video_id:
                        # Hi·ªÉn th·ªã video embed
                        st.video(f"https://www.youtube.com/watch?v={video_id}")
                    
                    # Hi·ªÉn th·ªã link c√≥ th·ªÉ click
                    st.markdown("**üì∫ Link YouTube:**")
                    st.markdown(
                        f'<a href="{source_url}" target="_blank" style="font-size: 16px; color: #FF0000; text-decoration: none;">üîó {source_url}</a>',
                        unsafe_allow_html=True
                    )
                else:
                    st.markdown("**üîó Link tham kh·∫£o:**")
                    st.markdown(
                        f'<a href="{source_url}" target="_blank" style="font-size: 16px; text-decoration: none;">üîó {source_url}</a>',
                        unsafe_allow_html=True
                    )
            elif answer_is_fallback:
                st.info("Ngu·ªìn tham kh·∫£o kh√¥ng ƒë∆∞·ª£c cung c·∫•p khi kh√¥ng t√¨m th·∫•y th√¥ng tin trong b·ªëi c·∫£nh.")
            else:
                st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ngu·ªìn tham kh·∫£o.")
            
            st.markdown("---")
    
    elif submit_button and not query:
        st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n!")
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: gray;'>
        <p>H·ªá th·ªëng RAG v·ªõi Streamlit | Powered by Gemini, ChromaDB, Sentence Transformers</p>
    </div>
    """, unsafe_allow_html=True)

# =======================================================
# CH·∫†Y APP
# =======================================================
if __name__ == "__main__":
    main()

